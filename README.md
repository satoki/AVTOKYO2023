# AVTOKYO2023 Talks

## AIチャットボットに対する Prompt Injection と Filter Bypass
**講演概要：** Prompt Injection Attackとは、AIチャットボットに対して特殊な指示を入力することで、開発者/運用者の意図しない出力を発生させる攻撃です。この攻撃により、AIチャットボットに含まれる機密情報を盗み出すことや、非倫理的な言動を引き起こしサイトレピュテーションを低下させることが可能となります。
大規模言語モデルを用いたAIチャットボットサービスは将来的に増加すると考えられ、脆弱性診断員はそれらチャットボットの診断テクニックを習得する必要があります。チャットボットにはルールベースでのフィルタ機能が導入されている場合が多く、不正な入力や非倫理的/機密情報の出力をブロックしますが、それで十分でしょうか？
本発表では、Prompt Injection Attack用の"やられサイト"の運営から得られたペイロードや入出力フィルタのバイパステクニックを紹介します。

**講演者紹介：** Webアプリケーションつんつん職人。CTFプレイヤー、バグハンターとして活動。SECCON CTFの運営メンバ、AVTOKYO2020の登壇、DEF CON CTF Finalsへ出場。GoogleやFirefoxを含む多数のWebサイトやソフトウェアの脆弱性を発見し報告している。

**[PDF (Japanese)]()**  

## Defeat the LLM: Techniques for Prompt Injection and Filter Bypass in AI
**Abstract :** A Prompt Injection Attack is an assault where special instructions are inputted into an AI chatbot, resulting in outputs not intended by the  developer/operator. Through this attack, one can potentially steal  confidential information stored within the AI chatbot or induce it to engage in unethical behaviors, thereby damaging the site's reputation.
It is expected that AI chatbot services using large-scale language models will increase in the future. Vulnerability assessors must thus learn diagnostic techniques for these chatbots. Many chatbots  incorporate rule-based filtering functions to block malicious inputs or outputs of unethical/confidential information. But is that enough?
In this presentation, we will introduce payloads and bypass techniques  for input/output filters, gleaned from managing a CTF (Capture The Flag) for Prompt Injection Attacks.

**Speakers Bio :** Cybersecurity Enthusiast, CTF Player and Bug Hunter. Contributed to the organization of SECCON CTF, took the stage at AVTOKYO2020, and competed in the DEF CON CTF Finals. Renowned for uncovering  vulnerabilities in high-profile platforms, having reported issues in the likes of Google and Firefox.

**[PDF (English)]()**  